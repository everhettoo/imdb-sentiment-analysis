{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To build sentiment analysis based on dataset from: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# To download spacy corpus. Please enable one of the required.\n",
    "# For bash shell\n",
    "! python -m spacy download en_core_web_sm\n",
    "\n",
    "#  For windows\n",
    "# %% python -m spacy download en"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's explore the dataset to understand the features before preparing for building the sentiment prediction models."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:01:42.308466Z",
     "start_time": "2025-03-16T04:01:42.306367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the datasets used in stages for building the models.\n",
    "raw_dataset_path = 'data/imdb-movie-review-kaggle-laskhmipathi.csv'\n",
    "\n",
    "# After encoding the classes to binary values (1: positive and 0: negative).\n",
    "encoded_dataset_path = 'data/1-imdb-movie-review-encoded.csv'\n",
    "\n",
    "# The final preprocessed files for building the models.\n",
    "processed_dataset_path = 'data/2-imdb-movie-review-processed.csv'"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:01:46.118493Z",
     "start_time": "2025-03-16T04:01:45.707048Z"
    }
   },
   "source": [
    "# Let's glance at the dataset.\n",
    "data = pd.read_csv(raw_dataset_path, encoding=\"ISO-8859-1\")\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:01:48.562391Z",
     "start_time": "2025-03-16T04:01:48.554269Z"
    }
   },
   "source": [
    "# The dataset has the following data types.\n",
    "data.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Let's investigate if the dataset has missing values.\n",
    "data.isnull().sum()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Let's investigate the distribution sentiment class distribution.\n",
    "data['sentiment'].value_counts()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# The dataset has well-balanced classes for positive and negative sentiment (1:1).\n",
    "# Let's visualize it in a bar chart.\n",
    "data['sentiment'].value_counts().plot.bar()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying special character in the dataset\n",
    "We will explore the noise in the data before building the model in this section. \\\n",
    "We will remove the noise during the preprocessing later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperlink"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:01:56.393858Z",
     "start_time": "2025-03-16T04:01:55.572456Z"
    }
   },
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Define a regex pattern for URLs\n",
    "url_pattern = r'https?://(?:www\\.)?\\S+'\n",
    "\n",
    "# Let's explore whether the dataset contains hyperlinks.\n",
    "temp = []\n",
    "for index, row in data.iterrows():\n",
    "    review_text = row['review']\n",
    "    text_list = re.findall(url_pattern, review_text)\n",
    "    if len(text_list) > 0:\n",
    "        temp.append(text_list)\n",
    "\n",
    "print(f'Dataset contains {len(temp)} number of hyperlinks.')\n",
    "tmp = pd.Series(temp)\n",
    "tmp.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 119 number of hyperlinks.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                         [http://www.invocus.net)]\n",
       "1           [http://blog.myspace.com/locoformovies]\n",
       "2    [http://www.comingsoon.net/films.php?id=36310]\n",
       "3                     [http://tinyurl.com/znyyq<br]\n",
       "4              [http://imdb.com/name/nm0834754/bio]\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Character"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:02:00.024958Z",
     "start_time": "2025-03-16T04:01:58.619018Z"
    }
   },
   "source": [
    "# Define a regex pattern for special character\n",
    "special_character = r'[#,.\\-$!/()?%_√Ø¬ø¬Ω:&|;]'\n",
    "\n",
    "# Let's explore whether the dataset contains special character.\n",
    "temp = []\n",
    "for index, row in data.iterrows():\n",
    "    review_text = row['review']\n",
    "    text_list = re.findall(special_character, review_text)\n",
    "    if len(text_list) > 0:\n",
    "        temp.append(text_list)\n",
    "\n",
    "print(f'Dataset contains {len(temp)} number of special characters.')\n",
    "tmp = pd.Series(temp)\n",
    "tmp.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 49992 number of special characters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [., ,, ., /, /, ,, ., ,, ., ,, ., ,, ., /, /, ...\n",
       "1    [., /, /, -, -, -, ,, ,, ., /, /, -, !, ,, ., ...\n",
       "2    [,, -, ., ,, (, ), ., :, ,, ., /, /, (, ?, ), ...\n",
       "3    [(, ), &, ., /, /, ., ., ., ,, ., /, /, ,, !, ...\n",
       "4    [., ., ., ,, ., /, /, ,, ., ,, ,, ., ,, ., ., ...\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:02:02.782936Z",
     "start_time": "2025-03-16T04:02:01.365747Z"
    }
   },
   "source": [
    "# Define a regex pattern for date\n",
    "date_pattern = r'\\d{1,4}[\\/\\-]\\d{1,2}[\\/\\-]\\d{1,4}'\n",
    "\n",
    "# Let's explore whether the dataset contains date.\n",
    "temp = []\n",
    "for index, row in data.iterrows():\n",
    "    review_text = row['review']\n",
    "    text_list = re.findall(date_pattern, review_text)\n",
    "    if len(text_list) > 0:\n",
    "        temp.append(text_list)\n",
    "\n",
    "print(f'Dataset contains {len(temp)} number of date.')\n",
    "tmp = pd.Series(temp)\n",
    "tmp.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 209 number of date.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      [4/25/08]\n",
       "1        [7-1/2]\n",
       "2    [5/28/2000]\n",
       "3       [7/3/40]\n",
       "4    [6/20/2009]\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stand Alone Number"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:02:06.492739Z",
     "start_time": "2025-03-16T04:02:05.068678Z"
    }
   },
   "source": [
    "# Define a regex pattern for stand-alone number\n",
    "number= r'\\d+'\n",
    "\n",
    "# Let's explore whether the dataset stand-alone number.\n",
    "temp = []\n",
    "for index, row in data.iterrows():\n",
    "    review_text = row['review']\n",
    "    text_list = re.findall(number, review_text)\n",
    "    if len(text_list) > 0:\n",
    "        temp.append(text_list)\n",
    "\n",
    "print(f'Dataset contains {len(temp)} stand alone number.')\n",
    "tmp = pd.Series(temp)\n",
    "tmp.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 28005 stand alone number.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         [1]\n",
       "1         [2]\n",
       "2     [3, 10]\n",
       "3    [15, 25]\n",
       "4        [10]\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## br, @"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:02:11.254622Z",
     "start_time": "2025-03-16T04:02:08.582973Z"
    }
   },
   "source": [
    "# Define a regex pattern for br (HTML break line) and @ (mention) tags\n",
    "number= r'\\bRT\\b|@[A-Za-z0-9_]+|\\bbr\\b'\n",
    "\n",
    "# Let's explore whether the dataset br mentions @.\n",
    "temp = []\n",
    "for index, row in data.iterrows():\n",
    "    review_text = row['review']\n",
    "    text_list = re.findall(number, review_text)\n",
    "    if len(text_list) > 0:\n",
    "        temp.append(text_list)\n",
    "\n",
    "print(f'Dataset contains {len(temp)} br, mentions @.')\n",
    "tmp = pd.Series(temp)\n",
    "tmp.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 29232 br, mentions @.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0            [br, br, br, br, br, br]\n",
       "1            [br, br, br, br, br, br]\n",
       "2                    [br, br, br, br]\n",
       "3            [br, br, br, br, br, br]\n",
       "4    [br, br, br, br, br, br, br, br]\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smiley"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:02:14.586545Z",
     "start_time": "2025-03-16T04:02:13.157066Z"
    }
   },
   "source": [
    "# Define a regex pattern for smileys\n",
    "smiley_pattern = r\"(:\\)|:-\\)|;d|:-E|:\\(|:-\\(|:-<|:-P|:O|:-@|:@|:-\\$|:\\\\|:#|:X|:\\^\\)|:-&|\\$_\\$|@@|:-!|:-D|:-0|O\\.O|<\\(-_-\\)>|d\\[-_-\\]b|;\\)|O:-\\)|O\\*\\)|\\(:-D\\)|=\\^.\\^=|\\^_\\^|:-?P|:-?O|:-?3|:-?\\])\"\n",
    "\n",
    "# Check for smileys in the dataset\n",
    "temp = []\n",
    "for index, row in data.iterrows():\n",
    "    review_text = row['review']\n",
    "    smiley_list = re.findall(smiley_pattern, review_text)\n",
    "    if smiley_list:\n",
    "        temp.append(smiley_list)\n",
    "\n",
    "print(f'Dataset contains {len(temp)} number of reviews with smileys.')\n",
    "tmp = pd.Series(temp)\n",
    "tmp.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 684 number of reviews with smileys.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [:)]\n",
       "1    [;)]\n",
       "2    [;)]\n",
       "3    [:3]\n",
       "4    [:3]\n",
       "dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contraction"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:02:19.077286Z",
     "start_time": "2025-03-16T04:02:16.835505Z"
    }
   },
   "source": [
    "# Define a regex pattern for contractions\n",
    "contraction_pattern = r\"\\b\\w+'\\w+\\b\"\n",
    "\n",
    "# Check for contractions in the dataset\n",
    "temp = []\n",
    "for index, row in data.iterrows():\n",
    "    review_text = row['review']\n",
    "    contractions_found = re.findall(contraction_pattern, review_text)\n",
    "    if contractions_found:\n",
    "        temp.append(contractions_found)\n",
    "\n",
    "print(f\"Dataset contains {len(temp)} reviews with contractions.\")\n",
    "tmp = pd.Series(temp)\n",
    "tmp.head()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 43839 reviews with contractions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [you'll, wouldn't, doesn't, couldn't, who'll, ...\n",
       "1                              [master's, Halliwell's]\n",
       "2                                 [I'd, Woody's, I've]\n",
       "3                           [there's, there's, you're]\n",
       "4                   [Mattei's, Schnitzler's, Mattei's]\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks, like the dataset has well-balanced classes for building the sentiment analysis. \\\n",
    "In this section, we will prepare the dataset for building the ML models by removing the noise in the data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:02:26.424785Z",
     "start_time": "2025-03-16T04:02:26.420161Z"
    }
   },
   "source": [
    "# Convert the sentiment classes from categorical to numeric representation.\n",
    "data[\"sentiment\"] = data[\"sentiment\"].map({\"positive\": 1, \"negative\": 0})"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:02:28.515340Z",
     "start_time": "2025-03-16T04:02:28.511985Z"
    }
   },
   "source": [
    "# Let's verify the data after conversion.\n",
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:03:00.278428Z",
     "start_time": "2025-03-16T04:02:59.591040Z"
    }
   },
   "source": [
    "# Save to new CSV with classes encoded\n",
    "data.to_csv(encoded_dataset_path, index=False)"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the identified noise in the dataset.\n",
    "#### NOTE: Takes around 15 to 30 minutes."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-16T04:32:05.796637Z",
     "start_time": "2025-03-16T04:05:44.851077Z"
    }
   },
   "source": [
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define spaCy's stop words\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "\n",
    "# Contractions dictionary\n",
    "contractions = {\n",
    "    \"can't\": \"cannot\", \"won't\": \"will not\", \"i'm\": \"i am\", \"she's\": \"she is\",\n",
    "    \"he's\": \"he is\", \"they're\": \"they are\", \"we're\": \"we are\", \"i've\": \"i have\",\n",
    "    \"you're\": \"you are\", \"they've\": \"they have\", \"i'd\": \"i would\", \"we'd\": \"we would\",\n",
    "    \"couldn't\": \"could not\", \"wouldn't\": \"would not\", \"shouldn't\": \"should not\",\n",
    "    \"don't\": \"do not\", \"haven't\": \"have not\", \"omg\": \"oh my god\",\n",
    "    \"aren't\": \"are not\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\", \"isn't\": \"is not\", \"it's\": \"it is\", \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\", \"mightn't\": \"might not\", \"might've\": \"might have\",\n",
    "    \"mustn't\": \"must not\", \"must've\": \"must have\", \"needn't\": \"need not\",\n",
    "    \"o'clock\": \"of the clock\", \"shan't\": \"shall not\", \"she'd\": \"she would\",\n",
    "    \"she'll\": \"she will\", \"that's\": \"that is\", \"there's\": \"there is\",\n",
    "    \"there'd\": \"there would\", \"they'd\": \"they would\", \"they'll\": \"they will\",\n",
    "    \"wasn't\": \"was not\", \"weren't\": \"were not\", \"what'll\": \"what will\",\n",
    "    \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\",\n",
    "    \"where's\": \"where is\", \"who'd\": \"who would\", \"who'll\": \"who will\",\n",
    "    \"who're\": \"who are\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\", \"would've\": \"would have\", \"you'd\": \"you would\",\n",
    "    \"you'll\": \"you will\", \"you've\": \"you have\", \"y'all\": \"you all\"\n",
    "}\n",
    "\n",
    "# Emojis dictionary\n",
    "emojis_dict = {\n",
    "    ':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad',\n",
    "    ':-(': 'sad', ':-<': 'sad', ':-P': 'raspberry', ':O': 'surprised',\n",
    "    ':-@': 'shocked', ':@': 'shocked', ':-$': 'confused', r':\\\\': 'annoyed',\n",
    "    ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
    "    '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.O': 'confused',\n",
    "    '<(-_-)>': 'robot', 'd[-_-]b': 'dj', ':-)': 'sadsmile', ';)': 'wink',\n",
    "    'O:-)': 'angel', 'O*)': 'angel', '(:-D': 'gossip', '=^.^=': 'cat'\n",
    "}\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # 1️⃣ Text Cleaning\n",
    "    text = re.sub(r'https?:\\/\\/[\\S]+', '', text)                # Remove hyperlinks\n",
    "    text = re.sub(r'[#,.\\-$!/()?%_√Ø¬ø¬Ω:&|;]', ' ', text)      # Replace special characters with a space\n",
    "    text = re.sub(r'@[A-Za-z0-9_]+', '', text)                  # Remove mentions\n",
    "    text = re.sub(r'\\d{1,4}[\\/\\-]\\d{1,2}[\\/\\-]\\d{1,4}', '', text) # Remove dates (e.g. 12/24/03)\n",
    "    text = re.sub(r'\\d+', '', text)                             # Remove standalone numbers\n",
    "    text = re.sub(r'\\bbr\\b', '', text)                          # Remove noise \"br\"\n",
    "\n",
    "\n",
    "    # 2️⃣ Contraction Expansion\n",
    "    for contraction, full_form in contractions.items():\n",
    "        text = re.sub(r'\\b' + re.escape(contraction) + r'\\b', full_form, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 3️⃣ Emoji Replacement\n",
    "    for emoji, meaning in emojis_dict.items():\n",
    "        text = text.replace(emoji, f' {meaning} ')\n",
    "    \n",
    "    # 4️⃣ Normalisation: convert to lowercase and remove extra spaces\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # 5️⃣ Tokenization, Lemmatisation, and Stopword Removal using spaCy\n",
    "    doc = nlp(text)\n",
    "    lemmatized_words = [token.lemma_ for token in doc]\n",
    "    filtered_words = [word for word in lemmatized_words if word not in stop_words and word.isalpha()]\n",
    "    \n",
    "    return \" \".join(filtered_words)\n",
    "\n",
    "# Read the CSV with encoding specified\n",
    "data = pd.read_csv(encoded_dataset_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Apply preprocessing to the \"review\" column\n",
    "data[\"review\"] = data[\"review\"].astype(str).apply(preprocess_text)\n",
    "\n",
    "# Display the processed dataset\n",
    "print(\"\\nProcessed Dataset:\")\n",
    "print(data.head().to_string())\n",
    "\n",
    "# Save the processed dataset into CSV\n",
    "data.to_csv(processed_dataset_path, index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed Dataset:\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                review  sentiment\n",
      "0  reviewer mention watch oz episode hook right exactly happen I thing strike I oz brutality unflinche scene violence set right word trust I faint hearted timid pull punch regard drug sex violence hardcore classic use word oz nickname oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass face inward privacy high agenda em city home aryan muslims gangstas latinos christians italian irish scuffle death stare dodgy dealing shady agreement far away I main appeal fact dare forget pretty picture paint mainstream audience forget charm forget romance oz mess episode I strike I nasty surreal I I ready I watch I develop taste oz accustom high level graphic violence violence injustice crook guard sell nickel inmate kill order away mannered middle class inmate turn prison bitch lack street skill prison experience watch oz comfortable uncomfortable view s touch dark          1\n",
      "1                                                                                                                                                                                                                                                                                                                                                                       wonderful little production filming technique unassuming old time bbc fashion comfort discomforte sense realism entire piece actor extremely choose michael sheen polari voice pat truly seamless editing guide reference williams diary entry worth watching terrificly write perform piece masterful production great master comedy life realism come home little thing fantasy guard use traditional dream technique remain solid disappear play knowledge sense particularly scene concern orton halliwell set particularly flat halliwell mural decorate surface terribly          1\n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                     I think wonderful way spend time hot summer weekend sit air condition theater watch light hearted comedy plot simplistic dialogue witty character likable bread suspect serial killer disappoint realize match point risk addiction I think proof woody allen fully control style grow love I laugh woody comedy year dare I decade I impress scarlet johanson manage tone sexy image jump right average spirited young woman crown jewel career witty devil wear prada interesting superman great comedy friend          1\n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               basically family little boy jake think zombie closet parent fight time movie slow soap opera suddenly jake decide rambo kill zombie ok film decide thriller drama drama movie watchable parent divorce argue like real life jake closet totally ruin film I expect boogeyman similar movie instead I watch drama meaningless thriller spot play parent descent dialog shot jake ignore          0\n",
      "4                                                                                                                                                                 petter mattei love time money visually stunning film watch mr mattei offer vivid portrait human relation movie tell money power success people different situation encounter variation arthur schnitzler play theme director transfer action present time new york different character meet connect connect way person know previous point contact stylishly film sophisticated luxurious look people live world live habitat thing soul picture different stage loneliness inhabit big city exactly good place human relation find sincere fulfillment discern case people encounter acting good mr mattei direction steve buscemi rosario dawson carol kane michael imperioli adrian grenier rest talented cast character come alive wish mr mattei good luck await anxiously work          1\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Exploratory data analysis after pre-processing"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Let's glance at the dataset.\n",
    "data = pd.read_csv(processed_dataset_path, encoding=\"ISO-8859-1\")\n",
    "data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# The dataset has the following rows and columns.\n",
    "data.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud - Positive Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Filter positive and negative sentiment reviews\n",
    "positive_text = \" \".join(data[data[\"sentiment\"] == 1][\"review\"])  # Positive sentiment\n",
    "\n",
    "# Create Word Clouds\n",
    "wordcloud_positive = WordCloud(width=1800, height=2000, background_color='black', colormap='Greens').generate(positive_text)\n",
    "\n",
    "# Plot Word Clouds\n",
    "plt.figure(figsize=(22, 18))\n",
    "\n",
    "# Positive Sentiment Word Cloud\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(wordcloud_positive, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Positive Sentiment Word Cloud\", fontsize=14)\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud Negative Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Filter positive and negative sentiment reviews\n",
    "negative_text = \" \".join(data[data[\"sentiment\"] == 0][\"review\"])  # Negative sentiment\n",
    "\n",
    "# Create Word Clouds\n",
    "wordcloud_negative = WordCloud(width=1800, height=2000, background_color='black', colormap='Reds').generate(negative_text)\n",
    "\n",
    "# Plot Word Clouds\n",
    "plt.figure(figsize=(22, 18))\n",
    "\n",
    "# Negative Sentiment Word Cloud\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(wordcloud_negative, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Negative Sentiment Word Cloud\", fontsize=14)\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "The dataset had few noise, we have explored them in the EDA and preprocessing sections. \\\n",
    "Next, we will use the preprocessed `data/2-imdb-movie-review-processed.csv` dataset for building the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
